<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc-markdown-css-theme" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Iterative¬†ùõº-(de)Blending: 2D tutorial</title>
  <link rel="stylesheet" href="css/theme.css" />
  <link rel="stylesheet" href="css/skylighting-paper-theme.css" />
</head>
<body>

<header>
<h1 class="title">Iterative¬†ùõº-(de)Blending: 2D tutorial</h1>
<blockquote class="metadata">
</blockquote>
</header>


<main>
<p>We provide a simple tutorial for <a
href="https://ggx-research.github.io/publication/2023/05/10/publication-iadb.html">Iterative
ùõº-(de)Blending</a> applied to 2D densities. We provide a Python code and
explain how it works below.</p>
<h2 id="data-loading">Data loading</h2>
<p>The objective is to create a mapping between two arbitrary
distributions <span class="math inline"><em>p</em><sub>0</sub></span>
and <span class="math inline"><em>p</em><sub>1</sub></span>. We provide
these distributions as grayscale PNG images p_0.png and p_1.png:</p>
<div style="display:flex; justify-content:center">
<div style="width:25%;margin-right: 2em;">
<center style="font-weight:800;">
p0.png
</center>
<p><img style="width:100%;" src="./images/p0.png"></p>
</div>
<div style="width:25%;">
<center style="font-weight:800;">
p1.png
</center>
<p><img style="width:100%;" src="./images/p1.png"></p>
</div>
</div>
<p>We start by loading these images and use a rejection sampling
algorithm to create a large number of samples <span
class="math inline"><em>x</em><sub>0</sub>‚ÄÑ‚àº‚ÄÑ<em>p</em><sub>0</sub></span>
and <span
class="math inline"><em>x</em><sub>1</sub>‚ÄÑ‚àº‚ÄÑ<em>p</em><sub>1</sub></span>:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># data loading</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>p_0 <span class="op">=</span> loadImage(<span class="st">&quot;p0.png&quot;</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>p_1 <span class="op">=</span> loadImage(<span class="st">&quot;p1.png&quot;</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>Ndata <span class="op">=</span> <span class="dv">65536</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>x_0_data <span class="op">=</span> generateSamplesFromImage(p_0, Ndata)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>x_1_data <span class="op">=</span> generateSamplesFromImage(p_1, Ndata)</span></code></pre></div>
<p>We provide the helper function generateSamplesFromImage() in the
code. This is what a random subset of the generated samples looks
like:</p>
<div style="display:flex; justify-content:center">
<div>
<center style="font-weight:800;margin-bottom: 0;">
<span class="math inline"><em>x</em><sub>0</sub></span>
</center>
<p><img style="width:100%;" src="./images/x0.png"></p>
</div>
<div>
<center style="font-weight:800;margin-bottom: 0;">
<span class="math inline"><em>x</em><sub>1</sub></span>
</center>
<p><img style="width:100%;" src="./images/x1.png"></p>
</div>
</div>
<h2 id="neural-network">Neural network</h2>
<p>We will train a neural network to learn the differential term (the
tangent) of the mapping between the samples <span
class="math inline"><em>x</em><sub>0</sub></span> and <span
class="math inline"><em>x</em><sub>1</sub></span>. A simple multi-layer
perceptron is enough for this 2D experiment. Note that the input
dimension is 2+1=3 because the inputs are the 2D <span
class="math inline"><em>x</em><sub><em>Œ±</em></sub></span> points with
their <span class="math inline"><em>Œ±</em></span> value.</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># architecture</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NN(torch.nn.Module):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear1 <span class="op">=</span> torch.nn.Linear(<span class="dv">2</span><span class="op">+</span><span class="dv">1</span>,<span class="dv">64</span>) <span class="co"># input = (x_alpha, alpha)</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear2 <span class="op">=</span> torch.nn.Linear(<span class="dv">64</span>, <span class="dv">64</span>)  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear3 <span class="op">=</span> torch.nn.Linear(<span class="dv">64</span>, <span class="dv">64</span>)   </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear4 <span class="op">=</span> torch.nn.Linear(<span class="dv">64</span>, <span class="dv">64</span>)   </span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.output  <span class="op">=</span> torch.nn.Linear(<span class="dv">64</span>, <span class="dv">2</span>)  <span class="co"># output = (x_1 - x_0)</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.relu <span class="op">=</span> torch.nn.ReLU()</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x, alpha):</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        res <span class="op">=</span> torch.cat([x, alpha], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        res <span class="op">=</span> <span class="va">self</span>.relu(<span class="va">self</span>.linear1(res))</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        res <span class="op">=</span> <span class="va">self</span>.relu(<span class="va">self</span>.linear2(res))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        res <span class="op">=</span> <span class="va">self</span>.relu(<span class="va">self</span>.linear3(res))</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        res <span class="op">=</span> <span class="va">self</span>.relu(<span class="va">self</span>.linear4(res))</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        res <span class="op">=</span> <span class="va">self</span>.output(res)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> res</span></code></pre></div>
<p>We allocate the neural network and its optimizer:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># allocating the neural network D</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> NN().to(<span class="st">&quot;cuda&quot;</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>optimizer_D <span class="op">=</span> torch.optim.Adam(D.parameters(), lr<span class="op">=</span><span class="fl">0.001</span>)</span></code></pre></div>
<h2 id="training">Training</h2>
<p>The training loop consists of sampling random <span
class="math inline"><em>x</em><sub>0</sub></span> and <span
class="math inline"><em>x</em><sub>1</sub></span>, blending them with
random <span class="math inline"><em>Œ±</em>‚ÄÑ‚àà‚ÄÑ[0,1]</span> to obtain
<span class="math inline"><em>x</em><sub><em>Œ±</em></sub></span>
samples, and training the network to predict <span
class="math inline"><em>x</em><sub>1</sub>‚ÄÖ‚àí‚ÄÖ<em>x</em><sub>0</sub></span>.</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># training loop</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>batchsize <span class="op">=</span> <span class="dv">256</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> iteration <span class="kw">in</span> tqdm(<span class="bu">range</span>(<span class="dv">65536</span>), <span class="st">&quot;training loop&quot;</span>):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">#</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    x_0 <span class="op">=</span> x_0_data[np.random.randint(<span class="dv">0</span>, Ndata, batchsize), :]</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    x_1 <span class="op">=</span> x_1_data[np.random.randint(<span class="dv">0</span>, Ndata, batchsize), :]</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> torch.rand(batchsize, <span class="dv">1</span>, device<span class="op">=</span><span class="st">&quot;cuda&quot;</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    x_alpha <span class="op">=</span> (<span class="dv">1</span><span class="op">-</span>alpha) <span class="op">*</span> x_0 <span class="op">+</span> alpha <span class="op">*</span> x_1</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> torch.<span class="bu">sum</span>( (D(x_alpha, alpha) <span class="op">-</span> (x_1<span class="op">-</span>x_0))<span class="op">**</span><span class="dv">2</span> )</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    optimizer_D.zero_grad()</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    optimizer_D.step()</span></code></pre></div>
<h2 id="sampling">Sampling</h2>
<p>Once the network is trained, we evaluate the mapping by starting from
random <span
class="math inline"><em>x</em><sub>0</sub>‚ÄÑ‚àº‚ÄÑ<em>p</em><sub>0</sub></span>
and moving the points along the direction predicted by the neural
network.</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sampling loop</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>batchsize <span class="op">=</span> <span class="dv">2048</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># starting points x_alpha = x_0</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    x_alpha <span class="op">=</span> x_0_data[np.random.randint(<span class="dv">0</span>, Ndata, batchsize), :]</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># loop</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> tqdm(<span class="bu">range</span>(T), <span class="st">&quot;sampling loop&quot;</span>):</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># export plot</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>        export(x_alpha, <span class="st">&quot;x_&quot;</span> <span class="op">+</span> <span class="bu">str</span>(t) <span class="op">+</span> <span class="st">&quot;.png&quot;</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># current alpha value</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        alpha <span class="op">=</span> t <span class="op">/</span> T <span class="op">*</span> torch.ones(batchsize, <span class="dv">1</span>, device<span class="op">=</span><span class="st">&quot;cuda&quot;</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># update </span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        x_alpha <span class="op">=</span> x_alpha <span class="op">+</span> <span class="dv">1</span><span class="op">/</span>T <span class="op">*</span> D(x_alpha, alpha)</span></code></pre></div>
<p>This is a GIF animation made with the exported plots.</p>
<div style="display:flex; justify-content:center">

<div>
<center style="font-weight:800;margin-bottom: 0;">
<span class="math inline"><em>x</em><sub>0</sub></span>
</center>
<p><img style="width:100%;" src="./images/x0.png"></p>
</div>
<div>
<center style="font-weight:800;margin-bottom: 0;">
<span class="math inline"><em>x</em><sub><em>Œ±</em></sub></span>
</center>
<p><img style="width:100%;" src="./images/x_alpha.gif"></p>
</div>
<div>
<center style="font-weight:800;margin-bottom: 0;">
<span class="math inline"><em>x</em><sub>1</sub></span>
</center>
<p><img style="width:100%;" src="./images/x1.png"></p>
</div>
</main>

<script>
;(function() {
  // Non-essential if user has JavaScript off. Just makes checkboxes look nicer.
  var selector = '.task-list > li > input[type="checkbox"]';
  var checkboxes = document.querySelectorAll(selector);
  Array.from(checkboxes).forEach((checkbox) => {
    var wasChecked = checkbox.checked;
    checkbox.disabled = false;
    checkbox.addEventListener('click', (ev) => {ev.target.checked = wasChecked});
  });
})();
</script>
</body>
</html>
